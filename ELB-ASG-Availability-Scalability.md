# AWS Fundamentals: ELB + ASG

## High Availability and Scalability

- Scalability means that an application/system can handle greater loads by adapting
- There are two kinds of scalability, vertical and horizontal (elasticity)
- Scalability is linked but different to High Availability

## Vertical Scalability

- Vertically scalability means increasing the size of the instance
- For example, your application runs on t2.micro
- Scaling that application vertically means running it on a t2.large
- Vertical scalability is very common for non distributed systems, such as a database
- RDS, ElastiCache are services that can scale vertically
- There’s usually a limit to how much you can vertically scale (hardware limit)

## Horizontal Scalability

- Horizontal Scalability means increasing the number of instances/systems for your application
- Horizontal scaling implies distributed systems
- This is very common for web applications/modern applications
- It’s easy to horizontally scale thanks to cloud offers such as Amazon EC2

## High Availability

- High availability usually goes hand in hand with horizontal scaling
- High availability means running your application/system in at least 2 data centres (availability zones)
- The goal of high availability is to survive a data centre loss
- The high availability can be passive (for RDS Multi AZ for example)
- The high availability can be active (for horizontal scaling)

### High Availability & Scaling for EC2

- Vertical scaling: increase instance size (scale up/down)
  - From t2.nano to u-12tb1.metal
- Horizontal scaling: increase number of instances (scale out/in)
  - Auto scaling group
  - Load balancer
- High availability: run instances for the same application across multi AZ
  - Auto scaling group multi az
  - Load balancer multi az

## Elastic Load Balancing (ELB)

- Load Balances are servers that forward traffic to multiple servers (ec2 instances) downstream
- Spread load across multiple downstream instances
- Expose a single point of access (DNS) to your application
- Seamlessly handle failures of downstream instances
- Do regular health checks to your instances
- Provide SSL termination (HTTPS) for your websites
- Enforce stickiness with cookies
- High availability across zones
- Separate public traffic from private traffic

### Elastic Load Balancer

- An Elastic Load Balancer is a managed load balancer
  - AWS guarantees that it will be working
  - AWS takes care of upgrades, maintenance, high availability
  - AWS provides only a few configuration knobs
- It costs less to set up your own load balancer but it will be a lot more effort on your end
- It is integrated with many AWS offers/services
  - EC2, EC2 Auto Scaling Groups, Amazon ECS
  - AWS Certificate Manager (ACM), CloudWatch
  - Route 53, AWS WAF, AWS Global Accelerator

### Health Checks

- Health Checks are crucial for Load Balancers
- They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
- The health check is done on a port and a route (/health is common)
- If the response is not 200 (OK), then the instance is unhealthy

### Types of Load Balancers on AWS

- Classic load balancer (v1 - old generation) - 2009 - CLB
  - HTTP, HTTPS, TCP, SSL (secure TCP)
- Application Load Balancer (v2 - new generation) - 2016 - ALB
  - HTTP, HTTPS, WebSocket
- Network Load Balancer (v2 - new generation) - 2017 - NLB
  - TCP, TLS (secure TCP), UDP
- Gateway Load Balancer - 2020 - GWLB
  - Operates at layer 3 (network layer) - IP Protocol
- Overall, it’s recommended to use the newer generation load balancer as they provide more features
- Some load balancers can be setup as internal (private) or external (public) ELBs

## Sticky Sessions (Session Affinity)

- It is possible to implement stickiness so that the same client is always redirected to the same instance behind a load balancer
- This works for Classic Load Balancer, Application Load Balancer and Network Load Balancer
- The “cookie” used for stickiness has an expiration date you control
- Use case: make sure the user doesn’t lose his session data
- Enabling stickiness may bring imbalance to the load over the backend EC2 instances
- Cookie names:
  - Application-based cookies
    - Custom cookie
      - Generated by the target
      - Can include any custom attribute required by the application
      - Cookie name must be specified individually for each target group
      - Doesn’t use AWSALB, AWSALBAPP or AWSALBTG (reserved for use by the eLB)
    - Application cookie
      - Generated by the load balancer
      - Cookie name is AWSALAPP
  - Duration-based Cookies
    - Cookie generated by the load balancer
    - Cookie name is AWSALB for ALB, AWSELB for CLB

## Cross Zone Balancing

- With cross zone load balancing: each load balancer instance distributes evenly across all registered instances in all AZ
- Without cross zone load balancing: requests are distributed in the instances of the node of the Elastic Load Balancer
- Application Load Balancer
  - Enabled by default (can be disabled at the target group level)
  - No charge for inter AZ data
- Network Load Balancer & Gateway Load Balancer
  - Disabled by default
  - You pay charge ($) for inter AZ data if enabled
- Classic Load Balancer
  - Disabled by default
  - No charges for inter AZ data if enabled

## SSL Certifications

- An SSL Certificate allows traffic between your clients and your load balancer to be encrypted in transit (in-flight encryption)
- SSL refers to secure sockets layer, used to encrypt connections
- TLS refers to transport layer security, which is a newer version
- Nowadays, TLS certificates are mainly used, but people still refer as SSL
- Public SSL certificates are issued by Certificate Authorities (CA)
- Comodo, Symantec, GoDaddy, GlobalSign, Digicert, Letsencrypt etc.
- SSL certificates have an expiration date (you set) and must be renewed
- The load balancer uses an X.509 certificate (SSL/TLS server certificate)
- You can manage certificates using ACM (AWS Certificate Manager)
- You can create upload your own certificates alternatively
- HTTPS listener:
  - You must specify a default certificate
  - You can add an optional list of certs to support multiple domains
  - Clients can use SNI (server name indication) to specify the hostname they reach
  - Ability to specify a security policy to support older versions of SSL/TLS (legacy clients)
- SNI solves the problem of loading multiple SSL certificates onto one web server (to serve mutable websites)
- It’s a “newer” protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake
- The server will then find the correct certificate, or return the default one
- Note: only works for ALB & NLB (newer generation) and CloudFront, doesn’t work for CLB (older generation)
- Classic Load Balancer (v1)
  - Support only one SSL certificate
  - Must use multiple CLB for multiple hostname with multiple SSL certificates
- Application Load Balancer (v2)
  - Supports multiple listeners with multiple SSL certificates
  - Uses Server Name Indication (SNI) to make it work
- Network Load Balancer (v2)
  - Supports multiple listeners with multiple SSL certificates

## Connection Draining

- Feature naming
  - Connection Draining - for CLB
  - Deregistration Delay - for ALB & NLB
- Time to complete “in-flight requests” while the instance is de-registering or unhealthy
- Stops sending new requests to the EC2 instance which is de-registering
- Between 1 to 3600 seconds (default is 300 seconds)
- Can be disabled (set value to 0)
- Set to a low value if your requests are short

## Application Load Balancer (ALB)

- Application load balancers is Layer 7 (HTTP)
- Load balancing to multiple HTTP applications across machines (target groups)
- Load balancing to multiple applications on the same machine (eg. Containers)
- Support for HTTP/2 and WebSocket
- Support redirects (from HTTP to HTTPS for example)
- Routing tables to different target groups
  - Routing based on path in URL
  - Routing based on hostname in URL
  - Routing based on query strings and headers
- ALB are a great fit for micro services & container based application
- Has a port mapping feature to redirect to a dynamic port in ECS
- In comparison, we’d need multiple Classic Load Balancer per application
- Fixed hostname (xxx.region.elb.amazonaws.com)
- The application servers don’t see the IP of the client directly
  - The true IP of the client is inserted in the header x-forwarded-for
  - We can also get post (x-forwarded=port) and port (x-forwarded-proto)

## Target Groups

- EC2 instances (can be managed by an Auto Scaling Group) - HTTP
- ECS tasks (managed by ECS itself) - HTTP
- Lambda functions - HTTP request is translated into JSON event
- IP Addresses - must be private IPs
- ALB can route to multiple target groups
- Health checks are at the target group level

## Network Load Balancer (NLB)

- Layer 4
- Forward TCP & UDP traffic to your instances
- Handle millions of requests per seconds
- Less latency ~100 ms (vs 400 ms for ALB)
- NLB has one static IP per AZ and support assigning Elastic IP (helpful for whitelisting specific IP)
- NLBs are used for extreme performance (TCP or UDP traffic)
- Not included in the AWS free tier

## Target Groups

- EC2 instances
- IP addresses - must be private IPs
- Application Load Balancer
- Health Checks support the TCP, HTTP and HTTPS protocols

## Gateway Load Balancer (GLB)

- Deploy, scale and manage a fleet of 3rd party network virtual appliances in AWS
- Example: firewalls, intrusion detection and prevention systems, deep packet inspection systems, payload manipulation
- Operates at Layer 3 (network layer) - IP packets
- Combines the following functions:
  - Transparent Network Gateway: single entry/exit for all traffic
  - Load Balancer: distributes traffic to your virtual appliances
- Uses the GENEVE protocol on port 6081

## Target Groups

- EC2 instances
- IP addresses - must be private

## Auto Scaling Groups (ASG)

- In real life, the load on your websites and applications can change
- In the cloud, you can create and get rid of servers very quickly
- The goal of an auto-scaling group (ASG) is to :
  - Scale out (add EC2 instances) to match an increased load
  - Scale in (remote EC2 instances) to match a decreased load
  - Ensure we have a minimum and a maximum number of EC2 instances running
  - Automatically register new instances to a load balancer
  - Re-create an EC2 instance in case a previous one is terminated (eg. If unhealthy)
- ASG are free (you only pay for the underlying EC2 instances)

## Group Attributes

- A launch template (older “Launch Configurations” are deprecated)
  - AMI + Instance Type
  - EC2 User Data
  - EBS Volumes
  - Security Groups
  - SSH Key Pair
  - IAM Roles for your EC2 instances
  - Network + Subnets information
  - Load Balancer Information
- Min Size/Max Size/Initial Capacity
- Scaling Policies

## CloudWatch Alarms & Scaling

- It is possible to scale an ASG based on CloudWatch alarms
- An alarm monitors a metric (such as Average CPU, or a custom metric)
- Metrics such as Average CPU are computed for the overall ASG instances
- Based on the alarm:
  - We can create scale-out policies (increase the number of instances)
  - We can create scale-in policies (decrease the number of instances)

## Scaling Policies

- Dynamic Scaling
  - Target Tracking Scaling
    - Simple to set-up
    - Example: I want the average ASG CPU to stay at around 40%
  - Simple/Set Scaling
    - When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units
    - When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
- Scheduled Scaling
  - Anticipate a scaling based on known usage patterns
  - Example: increase the min capacity to 10 at 5pm on Fridays
- Predictive scaling: continuously forecast load and schedule scaling ahead
- Good metrics to scale on:
  - CPUUtilisation: average CPU utilisation across your instances
  - RequestCountPerTarget: to make sure the number of requests per EC2 instances is stable
  - Average Network In/Out (if you’re application is network bound)
  - Any custom metric (that you push using CloudWatch)
- Scaling cooldowns:
  - After a scaling activity happens, you are in the cooldown period (default 300 seconds)
  - During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilise)
  - Advice: Use a read-to-use AMI to reduce configuration time in order to be serving requests faster and reduce the cooldown period

## Instance Refresh

- Goal: update launch template and then re-creating all EC2 instances
- For this we can use the native feature of Instance Refresh
- Setting of minimum healthy percentage
- Specify warm-up time (how long until the instance is ready to use)
